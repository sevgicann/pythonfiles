{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a decision tree with the training set.\n",
    "\n",
    "Drug<A>\n",
    "Drug<B>\n",
    "\n",
    "- age\n",
    " - young\n",
    "   - sex\n",
    "     - F <A>\n",
    "     - M <B>\n",
    " - middle age <B>\n",
    " - senior\n",
    "  - kolestrol\n",
    "    - high<A>\n",
    "    - normal<B>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Each \"Internal node\" corresponds to a test.\n",
    "- And each \"branch\" corresponds to a result of the test.\n",
    "- And each \"leaf node\" assigns a patient to a class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1- Choose an attribute from dataset.\n",
    "- 2- Calculate the significance of the attribute in the splitting of the data.\n",
    "- 3- Split the data based on the value of the best attribute. \n",
    "- 4- Go to step 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision trees are built using recursive partitioning to classify the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- More predictiveness\n",
    "- Less Impurity\n",
    "- Lower Entropi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Pure Node\": a node in the tree is considered pure if, in all of the cases, the nodes fall into a specific category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropi\n",
    "Information disorder or randomness in the data.\n",
    "The entropi is used to calculate the homogeneity of the samples in that node.\n",
    "# TODO Check entropi formul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tree with the higher information gain after splitting. InfÄ±rmation gain= Entropi before split - weighted entropi after split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
